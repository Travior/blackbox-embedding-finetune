{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class Question:\n",
    "    question: str\n",
    "    context_index: int\n",
    "    embedding: Optional[torch.tensor] = None\n",
    "    transformed_embedding: Optional[torch.tensor] = None\n",
    "\n",
    "@dataclass\n",
    "class Context:\n",
    "    context: str\n",
    "    context_index: int\n",
    "    embedding: Optional[torch.tensor] = None\n",
    "    transformed_embedding: Optional[torch.tensor] = None\n",
    "\n",
    "@dataclass\n",
    "class DataCollection:\n",
    "    questions: list[Question]\n",
    "    contexts: list[Context]\n",
    "    metadata: dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI text-embedding-3-large embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.Client(api_key=\"API KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/raw/2008_Sichuan_earthquake-base.pkl\n",
      "./data/raw/Antarctica-base.pkl\n",
      "./data/raw/Beyoncé-base.pkl\n",
      "./data/raw/dolly-base.pkl\n",
      "./data/raw/Frédéric_Chopin-base.pkl\n",
      "./data/raw/Hunting-base.pkl\n",
      "./data/raw/Pharmaceutical_industry-base.pkl\n",
      "./data/raw/sciq-base.pkl\n",
      "./data/raw/sciq-large-base.pkl\n"
     ]
    }
   ],
   "source": [
    "for path in list(glob.glob(\"./data/raw/*.pkl\")):\n",
    "    print(path)\n",
    "    if \"sciq-large\" not in path:\n",
    "        continue\n",
    "    with open(path, 'rb') as file:\n",
    "       data_collection: DataCollection = pickle.load(file) \n",
    "    questions = [q.question for q in data_collection.questions]\n",
    "    contexts = [c.context for c in data_collection.contexts]\n",
    "    for chunk in range(0, len(questions),1000):\n",
    "        question_embs = client.embeddings.create(\n",
    "            input=questions[chunk:chunk+1000],\n",
    "            model=\"text-embedding-3-large\"\n",
    "        )\n",
    "        for q, e in zip(data_collection.questions, question_embs.data):\n",
    "            q.embedding = torch.tensor(e.embedding)\n",
    "    for chunk in range(0, len(contexts),1000):\n",
    "        context_embs = client.embeddings.create(\n",
    "            input=contexts[chunk:chunk+1000],\n",
    "            model=\"text-embedding-3-large\"\n",
    "        )\n",
    "        for c, e in zip(data_collection.contexts, context_embs.data):\n",
    "            c.embedding = torch.tensor(e.embedding)\n",
    "    if not pathlib.Path(\"data/embedded/text-embedding-3-large/\").exists():\n",
    "        pathlib.Path(\"data/embedded/text-embedding-3-large/\").mkdir(parents=True)\n",
    "    with open(f\"data/embedded/text-embedding-3-large/{data_collection.metadata['category']}-embedded.pkl\", \"wb\") as file:\n",
    "        pickle.dump(data_collection, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI text-embedding-ada-002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/raw/2008_Sichuan_earthquake-base.pkl\n",
      "./data/raw/Antarctica-base.pkl\n",
      "./data/raw/Beyoncé-base.pkl\n",
      "./data/raw/dolly-base.pkl\n",
      "./data/raw/Frédéric_Chopin-base.pkl\n",
      "./data/raw/Hunting-base.pkl\n",
      "./data/raw/Pharmaceutical_industry-base.pkl\n",
      "./data/raw/sciq-base.pkl\n",
      "./data/raw/sciq-large-base.pkl\n"
     ]
    }
   ],
   "source": [
    "for path in glob.glob(\"./data/raw/*.pkl\"):\n",
    "    print(path)\n",
    "    if \"sciq-large\" not in path:\n",
    "        continue\n",
    "    with open(path, 'rb') as file:\n",
    "       data_collection: DataCollection = pickle.load(file) \n",
    "    questions = [q.question for q in data_collection.questions]\n",
    "    contexts = [c.context for c in data_collection.contexts]\n",
    "    for chunk in range(0, len(questions),1000):\n",
    "        question_embs = client.embeddings.create(\n",
    "            input=questions[chunk:chunk+1000],\n",
    "            model=\"text-embedding-ada-002\"\n",
    "        )\n",
    "        for q, e in zip(data_collection.questions, question_embs.data):\n",
    "            q.embedding = torch.tensor(e.embedding)\n",
    "    for chunk in range(0, len(contexts),1000):\n",
    "        context_embs = client.embeddings.create(\n",
    "            input=contexts[chunk:chunk+1000],\n",
    "            model=\"text-embedding-ada-002\"\n",
    "        )\n",
    "        for c, e in zip(data_collection.contexts, context_embs.data):\n",
    "            c.embedding = torch.tensor(e.embedding)\n",
    "    if not pathlib.Path(\"data/embedded/text-embedding-ada-002/\").exists():\n",
    "        pathlib.Path(\"data/embedded/text-embedding-ada-002/\").mkdir(parents=True)\n",
    "    with open(f\"data/embedded/text-embedding-ada-002/{data_collection.metadata['category']}-embedded.pkl\", \"wb\") as file:\n",
    "        pickle.dump(data_collection, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohere-embed-english-v3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = cohere.Client(\"API KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/raw/2008_Sichuan_earthquake-base.pkl\n",
      "./data/raw/Antarctica-base.pkl\n",
      "./data/raw/Beyoncé-base.pkl\n",
      "./data/raw/dolly-base.pkl\n",
      "./data/raw/Frédéric_Chopin-base.pkl\n",
      "./data/raw/Hunting-base.pkl\n",
      "./data/raw/Pharmaceutical_industry-base.pkl\n",
      "./data/raw/sciq-base.pkl\n",
      "./data/raw/sciq-large-base.pkl\n"
     ]
    }
   ],
   "source": [
    "for path in glob.glob(\"./data/raw/*.pkl\"):\n",
    "    print(path)\n",
    "    \n",
    "    with open(path, 'rb') as file:\n",
    "        data_collection: DataCollection = pickle.load(file)\n",
    "    questions = [q.question for q in data_collection.questions]\n",
    "    contexts = [c.context for c in data_collection.contexts]\n",
    "    question_embs = client.embed(\n",
    "        texts=questions,\n",
    "        model=\"embed-english-v3.0\",\n",
    "        input_type=\"search_query\"\n",
    "    )\n",
    "    context_embs = client.embed(\n",
    "        texts=contexts,\n",
    "        model=\"embed-english-v3.0\",\n",
    "        input_type=\"search_document\"\n",
    "    )\n",
    "    for q,e in zip(data_collection.questions, question_embs.embeddings):\n",
    "        q.embedding = torch.tensor(e)\n",
    "    for c,e in zip(data_collection.contexts, context_embs.embeddings):\n",
    "        c.embedding = torch.tensor(e)\n",
    "    if not pathlib.Path(\"data/embedded/Cohere-embed-english-v3.0/\").exists():\n",
    "        pathlib.Path(\"data/embedded/Cohere-embed-english-v3.0/\").mkdir(parents=True)\n",
    "    with open(f\"data/embedded/Cohere-embed-english-v3.0/{data_collection.metadata['category']}-embedded.pkl\", \"wb\") as file:\n",
    "        pickle.dump(data_collection, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAAI/bge-small-en-v1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('BAAI/bge-small-en-v1.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/raw/2008_Sichuan_earthquake-base.pkl\n",
      "./data/raw/Antarctica-base.pkl\n",
      "./data/raw/Beyoncé-base.pkl\n",
      "./data/raw/dolly-base.pkl\n",
      "./data/raw/Frédéric_Chopin-base.pkl\n",
      "./data/raw/Hunting-base.pkl\n",
      "./data/raw/Pharmaceutical_industry-base.pkl\n",
      "./data/raw/sciq-base.pkl\n",
      "./data/raw/sciq-large-base.pkl\n"
     ]
    }
   ],
   "source": [
    "for path in glob.glob(\"./data/raw/*.pkl\"):\n",
    "    print(path)\n",
    "    \n",
    "\n",
    "    with open(path, 'rb') as file:\n",
    "        data_collection: DataCollection = pickle.load(file)\n",
    "    instruction = \"Represent this sentence for searching relevant passages: \"\n",
    "    questions = [instruction+q.question for q in data_collection.questions]\n",
    "    contexts = [c.context for c in data_collection.contexts]\n",
    "    question_embs = model.encode(questions, normalize_embeddings=True)\n",
    "    context_embs = model.encode(contexts, normalize_embeddings=True)\n",
    "    for q,e in zip(data_collection.questions, question_embs):\n",
    "        q.embedding = torch.tensor(e)\n",
    "    for c,e in zip(data_collection.contexts, context_embs):\n",
    "        c.embedding = torch.tensor(e)\n",
    "    if not pathlib.Path(\"data/embedded/BAAI-bge-small-en-v1.5/\").exists():\n",
    "        pathlib.Path(\"data/embedded/BAAI-bge-small-en-v1.5/\").mkdir(parents=True)\n",
    "    with open(f\"data/embedded/BAAI-bge-small-en-v1.5/{data_collection.metadata['category']}-embedded.pkl\", \"wb\") as file:\n",
    "        pickle.dump(data_collection, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
